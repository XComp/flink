# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Workflow template for triggering the Flink's test suite.

name: "Build and Test Apache Flink"

on:
  workflow_call:
    inputs:
      workflow-caller-id:
        description: "The calling job's ID that can be used for build artifact names (that need to be different between different jobs of the same workflow)."
        default: ""
        type: string
      environment:
        description: "Defines environment variables for downstream scripts."
        required: true
        type: string
      jdk-version:
        description: "The Java version to use."
        default: 8
        type: number
      branch:
        description: "The branch the test suite should run on."
        default: "master"
        type: string
    secrets:
      s3_bucket:
        required: false
      s3_access_key:
        required: false
      s3_secret_key:
        required: false

permissions: read-all

env:
  # The working directory within the Docker container is set to /__w which is mapped to the runner
  # directory /home/runner/work.
  CONTAINER_WORKING_DIR: /__w/flink/flink
  MAVEN_REPO_FOLDER: /__w/flink/flink/.m2/repository
  MAVEN_ARGS: -Dmaven.repo.local=/__w/flink/flink/.m2/repository
  FLINK_ARTIFACT_DIR: /root/
  FLINK_ARTIFACT_FILENAME: flink_artifacts.tar.gz
  DOCKER_IMAGES_CACHE_FOLDER: /root/.docker-cache
  CHECKOUT_DIR: /root/flink

jobs:
  e2e:
    name: "E2E (group ${{ matrix.group }})"
    runs-on: ubuntu-latest
    if: ${{ needs.e2e-prereq-check.outputs.skip-e2e != 'true' }}
    # timeout-minutes: 310
    env:
      E2E_CACHE_FOLDER: ${{ github.workspace }}/.e2e-cache
      E2E_TARBALL_CACHE: ${{ github.workspace }}/.e2e-tarbal-cache
      MAVEN_REPO_FOLDER: ${{ github.workspace }}/.m2/repository
      MAVEN_ARGS: -Dmaven.repo.local=${{ github.workspace }}/.m2/repository
      FLINK_ARTIFACT_DIR: ${{ github.workspace }}
      FLINK_ARTIFACT_FILENAME: flink_artifacts.tar.gz
      DOCKER_IMAGES_CACHE_FOLDER: ${{ github.workspace }}/.docker-cache
    strategy:
      fail-fast: false
      matrix:
        group: [2]

    steps:
      - name: "Flink Checkout"
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.branch }}
          persist-credentials: false

      - name: "Set JDK version to Java ${{ inputs.jdk-version }}"
        uses: "./.github/actions/set_java_in_container"
        with:
          jdk-version: ${{ inputs.jdk-version }}

      - name: "Install missing packages"
        run: sudo apt-get install -y net-tools docker-compose

      - name: "Run E2E Tests"
        id: test-run
        env:
          IT_CASE_S3_BUCKET: ${{ secrets.s3_bucket }}
          IT_CASE_S3_ACCESS_KEY: ${{ secrets.s3_access_key }}
          IT_CASE_S3_SECRET_KEY: ${{ secrets.s3_secret_key }}
        # timeout-minutes: 310
        run: |
          export FLINK_DIR="$(pwd)"
          export END_TO_END_DIR="$FLINK_DIR/flink-end-to-end-tests"
          export TEST_DATA_DIR=$END_TO_END_DIR/test-scripts/temp-test-directory-$(date +%S%N)
          mkdir -p $TEST_DATA_DIR
          
          source flink-end-to-end-tests/test-scripts/common.sh
          set_conf_ssl "server"

      - name: "Print ${{ steps.test-run.outputs.debug-files-output-dir }}"
        run: |
          echo "environment variable: $DEBUG_FILES_OUTPUT_DIR"
          echo "Content"
          find $DEBUG_FILES_OUTPUT_DIR
          echo "github actions context: ${{ steps.test-run.outputs.debug-files-output-dir }}"
          echo "Content"
          find ${{ steps.test-run.outputs.debug-files-output-dir }}

      - name: "Upload Logs"
        uses: actions/upload-artifact@v3
        if: ${{ failure() && steps.test-run.outputs.debug-files-output-dir }} != ''
        with:
          name: logs-e2e-${{ needs.compile.outputs.stringified-workflow-name }}-${{ github.run_number }}-${{ matrix.group }}-${{ steps.test-run.outputs.debug-files-name }}
          path: ${{ steps.test-run.outputs.debug-files-output-dir }}

      - name: "Save Docker images to Cache"
        if: ${{ !cancelled() && (failure() || !steps.docker-cache.cache.hit) }}
        run: ./tools/azure-pipelines/cache_docker_images.sh -f ${{ env.DOCKER_IMAGES_CACHE_FOLDER }} save
